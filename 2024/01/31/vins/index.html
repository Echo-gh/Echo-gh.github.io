<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-48x48.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-32x32.png">
  <link rel="mask-icon" href="/images/favicon-32x32.svg" color="#222">
  <meta name="google-site-verification" content="kc32VCVuVpIaaxW7WxQc60wTHkpa97Q8gs-fFHJRVYM">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"echo-gh.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":false,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>





  <meta name="description" content="Qin, Tong, Peiliang Li, and Shaojie Shen. “VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator.” IEEE Transactions on Robotics 34, no. 4 (August 2018): 1004–20. https:&#x2F;&#x2F;doi.org">
<meta property="og:type" content="article">
<meta property="og:title" content="论文记录 VINS-Mono_A Robust and Versatile Monocular Visual-Inertial State Estimator">
<meta property="og:url" content="http://echo-gh.github.io/2024/01/31/vins/index.html">
<meta property="og:site_name" content="Echo&#39;s blog">
<meta property="og:description" content="Qin, Tong, Peiliang Li, and Shaojie Shen. “VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator.” IEEE Transactions on Robotics 34, no. 4 (August 2018): 1004–20. https:&#x2F;&#x2F;doi.org">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131090730704.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131094458729.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131103735319.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131104508327.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131104847991.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131105001484.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131105701602.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131111947126.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131112327470.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131151351640.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131152147563.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131152817355.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131152915603.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131153711975.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131154525405.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131160055792.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131160353726.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131161246881.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131162230978.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131163915327.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131170737502.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131172037799.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131174250572.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131193322044.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131194802806.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131200032028.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131200758379.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131204337669.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131203724102.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131204626147.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131204832609.png">
<meta property="og:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131205629702.png">
<meta property="article:published_time" content="2024-01-31T00:45:50.000Z">
<meta property="article:modified_time" content="2024-05-15T13:46:58.152Z">
<meta property="article:author" content="Echo">
<meta property="article:tag" content="SLAM">
<meta property="article:tag" content="C++">
<meta property="article:tag" content="IMU">
<meta property="article:tag" content="VINS">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://echo-gh.github.io/2024/01/31/vins/image-20240131090730704.png">

<link rel="canonical" href="http://echo-gh.github.io/2024/01/31/vins/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>论文记录 VINS-Mono_A Robust and Versatile Monocular Visual-Inertial State Estimator | Echo's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Echo's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-address-card fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-list fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-inbox fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://echo-gh.github.io/2024/01/31/vins/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/snoopy.jpg">
      <meta itemprop="name" content="Echo">
      <meta itemprop="description" content="To know, read. To learn, write. To master, teach.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Echo's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          论文记录 VINS-Mono_A Robust and Versatile Monocular Visual-Inertial State Estimator
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-01-31 08:45:50" itemprop="dateCreated datePublished" datetime="2024-01-31T08:45:50+08:00">2024-01-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-05-15 21:46:58" itemprop="dateModified" datetime="2024-05-15T21:46:58+08:00">2024-05-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/" itemprop="url" rel="index"><span itemprop="name">论文记录</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/SLAM/" itemprop="url" rel="index"><span itemprop="name">SLAM</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E8%AE%B0%E5%BD%95/SLAM/Multi-source/" itemprop="url" rel="index"><span itemprop="name">Multi-source</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Qin, Tong, Peiliang Li, and Shaojie Shen. “VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator.” <em>IEEE Transactions on Robotics</em> 34, no. 4 (August 2018): 1004–20. <a target="_blank" rel="noopener" href="https://doi.org/10.1109/TRO.2018.2853729">https://doi.org/10.1109/TRO.2018.2853729</a>.</p>
<h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><p>集成IMU 观测可通过减少由于光照变化、纹理稀少区域或运动模糊造成的视觉跟踪精度损失，来大幅提高运动跟踪的表现。但是，单目VINS (Visual-Inertial System) 在使用中也有一些问题需要解决：</p>
<ol>
<li>第一个问题是初始化困难：由于缺失直接的距离观测，很难直接将单目视觉结构与惯性测量进行融合；</li>
<li>其次是VINS 严重的非线性问题：这会在估计器初始化过程中带来巨大的挑战，再大部分场景中系统需要放置在一个位置已知的静态区域，然后缓慢小心地移动，这会极大限制系统的应用场景；</li>
<li>另一个问题是VIO 的长期漂移问题：为了消除累积漂移，会使用回环检测、重定位及全局优化技术；</li>
<li>此外还有对于地图保存与重使用的需求正在不断增长。</li>
</ol>
<span id="more"></span>
<p>为解决上述问题，作者提出了VINS-Mono 系统——一个鲁棒且多功能的单目视觉-惯性状态估计器，该系统包含以下特点：</p>
<ol>
<li><strong>鲁棒的初始化程序</strong>使得系统可以在未知状态进行启动；</li>
<li>紧耦合、基于优化的单目VIO 带有相机-IMU <strong>外参标定</strong>和IMU <strong>偏差校正</strong>；</li>
<li><strong>在线重定位</strong>以及4自由度的<strong>全局位姿图优化</strong>；</li>
<li>位姿图重用可<strong>保存、载入</strong>并<strong>融合</strong>多个局部位姿图。</li>
</ol>
<p>该系统已经成功应用于小规模的AR 场景、中规模的无人机导航，以及大规模的状态估计任务，如Fig. 1所示：</p>
<p><img src="/2024/01/31/vins/image-20240131090730704.png" alt="image-20240131090730704" title="figure 1"></p>
<h1 id="3-Overview"><a href="#3-Overview" class="headerlink" title="3 Overview"></a>3 Overview</h1><p>本文提出的单目视觉-惯性状态估计器的架构如Fig. 2所示，</p>
<p><img src="/2024/01/31/vins/image-20240131094458729.png" alt="image-20240131094458729" title="figure 2"></p>
<p>相较于适用于双目相机的SOTA 算法OKVIS，本算法是专为单目相机设计的，作者针对性设计了初始化程序、关键帧选取标准，并使用具有大视角的相机进行更好地跟踪；此外，本算法作为一个完整的系统还包含了回环检测以及位姿图重用模块。</p>
<p>本文的标注规则：</p>
<ul>
<li>$(.)^w$ 表示世界坐标系，重力方向与世界坐标系z 轴对齐；</li>
<li>$(.)^b$ 表示物体坐标系，与IMU 坐标系相同；</li>
<li>$(.)^c$ 表示相机坐标系；</li>
<li>使用旋转矩阵 $\mathbf{R}$ 和四元数 $\mathbf{q}$ 来表示旋转；</li>
<li>$\mathbf{q}^w_b$ 和 $\mathbf{p}^w_b$ 分别表示从物体坐标系到世界坐标系的旋转和平移；</li>
<li>$b_k$ 表示第<em>k</em> 张图片时刻的物体坐标系，$c_k$ 表示相机坐标系；</li>
<li>$\mathbf{g}^w = [0, 0, g]^T$ 是世界坐标系下的重力向量；</li>
<li>使用 $\hat{(.)}$ 表示某个参数的噪声观测或估计值。</li>
</ul>
<h1 id="4-Measurement-Preprocessing"><a href="#4-Measurement-Preprocessing" class="headerlink" title="4 Measurement Preprocessing"></a>4 Measurement Preprocessing</h1><p>观测预处理步骤：</p>
<ul>
<li>对于视觉观测：跟踪连续帧之间的特征，并在最新帧中检测新的特征；</li>
<li>对于IMU 观测：对连续帧之间的IMU 进行预积分。</li>
</ul>
<h2 id="4-1-Vision-Processing-Front-End"><a href="#4-1-Vision-Processing-Front-End" class="headerlink" title="4.1 Vision Processing Front End"></a>4.1 Vision Processing Front End</h2><p>对每张新图片，使用KLT 稀疏光流法来跟踪已有的特征；此外，检测新的角点特征来维持图片的最小特征数量（100-300）。探测器通过设定一个特征间最小像素间隔来执行特征均匀提取，2D 特征首先经过去畸变、外点剔除，然后投影至一个单位球上，外点剔除是通过RANSAC 方法实现的。</p>
<p>关键帧选取标准有两个：</p>
<ol>
<li><strong>较前一个关键帧的平均视差</strong>：若当前帧与上一个关键帧之间的平均视差超过一定阈值，则将当前帧设为关键帧；值得注意的是，平移与旋转均可以造成视差，但是纯旋转运动无法对特征进行三角化，为解决该问题，作者在计算视差时使用短期的<strong>陀螺仪观测来补偿旋转</strong>，需要说明的是，旋转补偿只用于关键帧选取，并不用于VINS 的旋转计算。</li>
<li><strong>跟踪质量</strong>：如果当前帧跟踪到的特征数量低于一个阈值，则将当前帧设为关键帧。</li>
</ol>
<h2 id="4-2-IMU-Preintegration"><a href="#4-2-IMU-Preintegration" class="headerlink" title="4.2 IMU Preintegration"></a>4.2 IMU Preintegration</h2><p>作者使用之前工作中用的连续时间基于四元数的IMU 预积分推导方法。</p>
<h3 id="4-2-1-IMU-Noise-and-Bias"><a href="#4-2-1-IMU-Noise-and-Bias" class="headerlink" title="4.2.1 IMU Noise and Bias"></a>4.2.1 IMU Noise and Bias</h3><p>IMU 的观测信息是在<strong>物体坐标系</strong>下的，包含重力和平台的运动信息，此外，观测还包含加速度偏差 $\mathbf{b}_a$ 、陀螺仪偏差 $\mathbf{b}_w$ 以及额外噪声，陀螺仪和加速度计的原始观测量 $\hat{\mathcal{w}}, \hat{\mathcal{a}}$ 如下所示：</p>
<p><img src="/2024/01/31/vins/image-20240131103735319.png" alt="image-20240131103735319" title="formula 1"></p>
<p>作者假设加速度计和陀螺仪的观测噪声服从高斯分布：$\mathbf{n}_a\sim\mathcal{N}(0, \sigma_a^2), \mathbf{n}_w\sim\mathcal{N}(0, \sigma_w^2)$ ；偏差 $\mathbf{b}_a$ 、 $\mathbf{b}_w$ 被建模为<strong>随机游走</strong>，其对应导数为高斯白噪声，$\mathbf{n}_{b_a}\sim\mathcal{N}(0, \sigma_{b_a}^2), \mathbf{n}_{b_w}\sim\mathcal{N}(0, \sigma_{b_w}^2)$ 。</p>
<p><img src="/2024/01/31/vins/image-20240131104508327.png" alt="image-20240131104508327" title="formula 2"></p>
<h3 id="4-2-2-Preintegration"><a href="#4-2-2-Preintegration" class="headerlink" title="4.2.2 Preintegration"></a>4.2.2 Preintegration</h3><p>连续两帧图片 $b_k, b_{k+1}$ 之间存在多组惯性观测数据，给定偏差估计，在局部坐标系 $b_k$ 中进行积分：</p>
<p><img src="/2024/01/31/vins/image-20240131104847991.png" alt="image-20240131104847991" title="formula 3"></p>
<p>其中：</p>
<p><img src="/2024/01/31/vins/image-20240131105001484.png" alt="image-20240131105001484" title="formula 4"></p>
<p>$\alpha, \beta, \gamma$ 的协方差 $\mathbf{P}_{b_{k+1}}^{b_k}$ 也进行相应传递；可以看出预积分项（式3）可通过给定 $b_k$ 作为偏差的参考坐标系，仅用IMU 观测即可获取。</p>
<h3 id="4-2-3-Bias-Correction"><a href="#4-2-3-Bias-Correction" class="headerlink" title="4.2.3 Bias Correction"></a>4.2.3 Bias Correction</h3><p>如果偏差估计改变量较小，利用一阶导数近似进行调整：</p>
<p><img src="/2024/01/31/vins/image-20240131105701602.png" alt="image-20240131105701602" title="formula 5"></p>
<p>如果偏差估计改变量较大，则在新的偏差估计下进行传递。该策略可为基于优化的算法节省大量计算资源，因为不需要重复进行IMU 观测传递。</p>
<h1 id="5-Estimator-Initialization"><a href="#5-Estimator-Initialization" class="headerlink" title="5 Estimator Initialization"></a>5 Estimator Initialization</h1><p>单目相机紧耦合的VIO 是一个高非线性系统，需要在开始时刻进行准确的初始化估计。作者通过将IMU 预积分和视觉观测进行松对齐来获取必要的初始估计值。</p>
<h2 id="5-1-Vision-Only-SfM-in-Sliding-Window"><a href="#5-1-Vision-Only-SfM-in-Sliding-Window" class="headerlink" title="5.1 Vision-Only SfM in Sliding Window"></a>5.1 Vision-Only SfM in Sliding Window</h2><p>作者控制滑动窗口内的图像帧数来限制计算复杂度，SfM 过程采取以下步骤：</p>
<ol>
<li>首先，确定当前帧与窗口内所有历史帧之间的特征关联，如果可以找到稳定的特征跟踪（超过30个跟踪特征）以及充分的视差（超过20像素），则可利用five-point 算法获取两帧之间的相对旋转和位移；</li>
<li>然后，随意设定尺度参数，对两帧中的所有跟踪特征进行三角化，基于三角化特征，使用PnP 算法来估计窗口内其他所有帧的位姿；</li>
<li>最终，利用全局BA 来最小化所有观测特征的重投影误差。</li>
</ol>
<p>由于尚未确定世界坐标系，所以将第一帧图片的位姿 $(.)^{c_0}$ 作为SfM 的参考坐标系，所有图片代表的相机位姿 $(\overline{\mathbf{p}}_{c_k}^{c_0}, \mathbf{q}_{c_k}^{c_0})$ 和特征位置都表示为 $(.)^{c_0}$ 的相对量，给定相机和IMU 之间的外参 $(\mathbf{p}_c^b, \mathbf{q}_c^b)$ ，可将相机位姿从相机坐标系转换至物体坐标系：</p>
<p><img src="/2024/01/31/vins/image-20240131111947126.png" alt="image-20240131111947126" title="formula 6"></p>
<p>其中，<em>s</em> 是未知的尺度参数。</p>
<h2 id="5-2-Visual-Inertial-Alignment"><a href="#5-2-Visual-Inertial-Alignment" class="headerlink" title="5.2 Visual-Inertial Alignment"></a>5.2 Visual-Inertial Alignment</h2><p>视觉-惯性的对齐过程如Fig. 3所示，基本想法是将视觉SfM 和IMU 预积分匹配起来。</p>
<p><img src="/2024/01/31/vins/image-20240131112327470.png" alt="image-20240131112327470" title="figure 3"></p>
<h3 id="5-2-1-Gyroscope-Bias-Calibration"><a href="#5-2-1-Gyroscope-Bias-Calibration" class="headerlink" title="5.2.1 Gyroscope Bias Calibration"></a>5.2.1 Gyroscope Bias Calibration</h3><p>假设从SfM 获取窗口内连续两帧 $b_k, b_{k+1}$ 的<strong>旋转参数</strong> $\mathbf{q}_{b_k}^{c_0}, \mathbf{q}_{b_k+1}^{c_0}$ ，以及从IMU 预积分中获取两者之间的<strong>相对约束</strong> $\hat{\gamma}^{b_k}_{b_{k+1}}$ ，作者将IMU 预积分项做关于陀螺仪偏差的<strong>线性化</strong>，并最小化下面的<strong>损失方程</strong>：</p>
<p><img src="/2024/01/31/vins/image-20240131151351640.png" alt="image-20240131151351640" title="formula 7"></p>
<p>其中，$\mathcal{B}$ 表示窗口内的所有图像帧。这样可以得到陀螺仪偏差 $\mathbf{b}_w$ 的初始标定值，然后使用新的陀螺仪偏差来传递所有的IMU 预积分项 $\hat{\alpha}^{b_k}_{b_{k+1}}, \hat{\beta}^{b_k}_{b_{k+1}}, \hat{\gamma}^{b_k}_{b_{k+1}}$ 。</p>
<h3 id="5-2-2-Velocity-Gravity-Vector-and-Metric-Scale-Initialization"><a href="#5-2-2-Velocity-Gravity-Vector-and-Metric-Scale-Initialization" class="headerlink" title="5.2.2 Velocity, Gravity Vector, and Metric Scale Initialization"></a>5.2.2 Velocity, Gravity Vector, and Metric Scale Initialization</h3><p>在对陀螺仪偏差进行初始化之后，继续对其他导航状态参数进行初始化，包括<strong>速度</strong>、<strong>重力向量</strong>以及<strong>尺度参数</strong>。</p>
<p><img src="/2024/01/31/vins/image-20240131152147563.png" alt="image-20240131152147563" title="formula 8"></p>
<p>其中，$\mathbf{v}_{b_k}^{b_k}$ 为第<em>k</em> 张图片时在物体坐标系中的速度；$\mathbf{g}^{c_0}$ 表示 $c_0$ 帧的重力向量；<em>s</em> 代表单目SfM 的尺度单位。</p>
<p>对于窗口内的连续两帧 $b_k, b_{k+1}$ ，有以下等式表示：</p>
<p><img src="/2024/01/31/vins/image-20240131152817355.png" alt="image-20240131152817355" title="formula 9"></p>
<p>结合式6和式9，得到以下的线性观测模型：</p>
<p><img src="/2024/01/31/vins/image-20240131152915603.png" alt="image-20240131152915603" title="formula 10-11"></p>
<p>其中，$\mathbf{R}_{b_k}^{c_0}, \mathbf{R}_{b_{k+1}}^{c_0}, \overline{\mathbf{p}}_{c_k}^{c_0}, \overline{\mathbf{p}}_{c_{k+1}}^{c_0}$ 可从单目视觉SfM 获取；$\Delta t_k$ 表示连续两帧的时间间隔。通过求解下面的最小二乘问题可得到每一帧图片代表的物体坐标系下的<strong>速度参数</strong>、视觉参考坐标系下的<strong>重力向量</strong>，以及<strong>尺度参数</strong>：</p>
<p><img src="/2024/01/31/vins/image-20240131153711975.png" alt="image-20240131153711975" title="formula 12"></p>
<h3 id="5-2-3-Gravity-Refinement"><a href="#5-2-3-Gravity-Refinement" class="headerlink" title="5.2.3 Gravity Refinement"></a>5.2.3 Gravity Refinement</h3><p>从上述线性初始化中获取的重力向量可通过<strong>约束数值大小</strong>进行细调，大部分情况下重力向量的大小是已知的，这就导致该重力向量是2自由度的，因此，作者使用正切空间中的两个向量对重力进行扰动：$g(\hat{\overline{\mathbf{g}}} + \delta \mathbf{g}, \delta \mathbf{g} = w_1\mathbf{b}_1 + w_2\mathbf{b}_2)$，其中，<em>g</em> 为重力的已知大小，$\hat{\overline{\mathbf{g}}}$ 表示重力方向的单位向量，$\mathbf{b}_1, \mathbf{b}_2$ 为正切平面上的两个正交偏差，如Fig. 4所示，$w_1, w_2$ 为两个方向上的扰动值。</p>
<p><img src="/2024/01/31/vins/image-20240131154525405.png" alt="image-20240131154525405" title="figure 4"></p>
<p>使用 $g(\hat{\overline{\mathbf{g}}} + \delta \mathbf{g})$ 替代式9中的 $\mathbf{g}$ ，与其他参数共同求解2自由度的 $\delta \mathbf{g}$ 。</p>
<h3 id="5-2-4-Completing-Initialization"><a href="#5-2-4-Completing-Initialization" class="headerlink" title="5.2.4 Completing Initialization"></a>5.2.4 Completing Initialization</h3><p>在细调重力向量之后，通过将重力向量对齐世界坐标系的<em>z</em> 轴，来获取世界坐标系和相机坐标系 $c_0$ 之间的旋转参数 $\mathbf{q}_{c_0}^w$ ，然后即可将获取到的所有参数从相机坐标系转换至世界坐标系。至此，系统初始化完成。</p>
<h1 id="6-Tightly-Coupled-Monocular-VIO"><a href="#6-Tightly-Coupled-Monocular-VIO" class="headerlink" title="6 Tightly Coupled Monocular VIO"></a>6 Tightly Coupled Monocular VIO</h1><p>基于滑动窗口的紧耦合单目VIO 进行高精度与鲁棒状态估计，过程如Fig. 5所示：</p>
<p><img src="/2024/01/31/vins/image-20240131160055792.png" alt="image-20240131160055792" title="figure 5"></p>
<h2 id="6-1-Formulation"><a href="#6-1-Formulation" class="headerlink" title="6.1 Formulation"></a>6.1 Formulation</h2><p>滑动窗口内的状态向量定义为：</p>
<p><img src="/2024/01/31/vins/image-20240131160353726.png" alt="image-20240131160353726" title="formula 13"></p>
<p>其中，$\mathbf{x}_k$ 表示第<em>k</em> 张图片代表的IMU 状态，包含世界坐标系下的位置、速度及朝向，以及IMU 物体坐标系下的加速度偏差和陀螺仪偏差；<em>n</em> 表示关键帧的总数；<em>m</em> 表示窗口内的特征总数；$\lambda_l$ 表示第 <em>l</em> 个特征在首次观测的逆距离。</p>
<p>作者使用视觉-惯性BA 方程，最小化先验和所有观测残差M 范数的总和来获取最大后验估计：</p>
<p><img src="/2024/01/31/vins/image-20240131161246881.png" alt="image-20240131161246881" title="formula 14"></p>
<p>其中，$\mathbf{r}_{\mathcal{B}}, \mathbf{r}_{\mathcal{C}}$ 分别表示IMU 和视觉观测的残差；$\mathcal{B}$ 表示所有的IMU 观测；$\mathcal{C}$ 表示当前滑动窗口内至少被观测2次的特征集合；$\{\mathbf{r}_p, \mathbf{H}_p\}$ 表示边缘化先验信息。本系统使用Ceres 求解非线性问题。</p>
<h2 id="6-2-IMU-Measurement-Residual"><a href="#6-2-IMU-Measurement-Residual" class="headerlink" title="6.2 IMU Measurement Residual"></a>6.2 IMU Measurement Residual</h2><p>考虑在窗口内连续两帧间 $b_k, b_{k+1}$ 的IMU 观测，其预积分残差可被定义为：</p>
<p><img src="/2024/01/31/vins/image-20240131162230978.png" alt="image-20240131162230978" title="formula 16"></p>
<p>其中，$[.]_{xyz}$ 表示提取误差状态表示四元数的向量部分；$\delta \theta ^{b_k}_{b_{k+1}}$ 表示四元数的3D 误差状态表示； $[\hat{\alpha}^{b_k}_{b_{k+1}}, \hat{\beta}^{b_k}_{b_{k+1}}, \hat{\gamma}^{b_k}_{b_{k+1}}]$ 表示IMU 预积分观测项。</p>
<h2 id="6-3-Visual-Measurement-Residual"><a href="#6-3-Visual-Measurement-Residual" class="headerlink" title="6.3 Visual Measurement Residual"></a>6.3 Visual Measurement Residual</h2><p>相较于传统针孔相机模型将重投影误差定义在一个图像平面上的做法，本文作者将<strong>相机观测残差定义在一个单位球上</strong>。几乎所有类型相机的光学特性（包括广角相机、鱼眼相机、全向相机等）都可以建模为连接单位球表面的单位射线。假设第 $l$ 个特征是在第 $i$ 帧图片被首次观测到，则该特征在第 $j$ 帧图片上的观测残差定义为：</p>
<p><img src="/2024/01/31/vins/image-20240131163915327.png" alt="image-20240131163915327" title="formula 17"></p>
<p>其中，$[\hat{u}^{c_i}_l, \hat{v}^{c_i}_l]$ 表示第 $l$ 个特征在第 $i$ 帧图片被首次观测到的像素坐标；$[\hat{u}^{c_j}_l, \hat{v}^{c_j}_l]$ 表示该特征在图片 $j$ 中的像素坐标；由于视觉残差是2自由度的，所以作者将残差向量投影至正切平面，$\mathbf{b}_1, \mathbf{b}_2$ 表示 $\hat{\overline{\mathcal{P}}}^{c_j}_l$ 正切平面上的两个正交向量，如Fig. 6所示；式14中的协方差 $\mathbf{P}_l^{c_j}$ 也从像素坐标系传递至单位球上。</p>
<p><img src="/2024/01/31/vins/image-20240131170737502.png" alt="image-20240131170737502" title="figure 6"></p>
<h2 id="6-4-Marginalization"><a href="#6-4-Marginalization" class="headerlink" title="6.4 Marginalization"></a>6.4 Marginalization</h2><p>为了限制计算复杂度，作者使用边缘化策略，有选择性地从滑动窗口中边缘化掉IMU 状态 $\mathbf{x}_k$ 和特征 $\lambda_l$ ，同时将对应观测的边缘状态量转换为先验信息。边缘化过程如Fig. 7所示，作者选择不边缘化掉非关键帧的所有观测是为了保持系统的稀疏性；本系统的边缘化策略是为了保持窗口内关键帧的分隔状态，以保证特征三角化所需的充分视差，以及大激励加速度计观测的概率。边缘化是通过Schur complement 实现的。</p>
<p><img src="/2024/01/31/vins/image-20240131172037799.png" alt="image-20240131172037799" title="figure 7"></p>
<h2 id="6-5-Motion-Only-Visual-Inertial-Optimization-for-Camera-Rate-State-Estimation"><a href="#6-5-Motion-Only-Visual-Inertial-Optimization-for-Camera-Rate-State-Estimation" class="headerlink" title="6.5 Motion-Only Visual-Inertial Optimization for Camera-Rate State Estimation"></a>6.5 Motion-Only Visual-Inertial Optimization for Camera-Rate State Estimation</h2><p>由于非线性优化对算力的要求，低算力设备（如手机等）上的紧耦合单目VIO 无法实现相机采集率级别的输出，因此，除了full optimization 外，作者还实现了一个轻量级motion-only visual-inertial 优化来提高状态估计的速率至30Hz。</p>
<p>该轻量级优化方法的损失函数与单目VIO 相同（式14），但不会优化窗口内的所有参数，而是只优化几个的最新IMU 状态的位姿与速度；在优化中会使用所有的视觉和惯性观测信息，这会实现较单帧 PnP 方法更为顺滑的状态估计解，该方法的介绍如Fig. 8所示。</p>
<p><img src="/2024/01/31/vins/image-20240131174250572.png" alt="image-20240131174250572" title="figure 8"></p>
<p>两种优化方法的速度对比：在最新的嵌入式电脑中，full optimization 的处理时间约为50ms，而该轻量级优化的处理时间约为5ms。</p>
<h2 id="6-6-IMU-Forward-Propagation-for-IMU-Rate-State-Estimation"><a href="#6-6-IMU-Forward-Propagation-for-IMU-Rate-State-Estimation" class="headerlink" title="6.6 IMU Forward Propagation for IMU-Rate State Estimation"></a>6.6 IMU Forward Propagation for IMU-Rate State Estimation</h2><p>本文提出的VIO 输出频率被限制到相机采集速率上，但是仍然可以使用附近的IMU 观测信息来直接传递最新的VIO 估计，以实现IMU 采集速率级别的输出表现。高速率状态估计可被用于回环的状态反馈，作者使用该方法测试了无人机飞行试验。</p>
<h1 id="7-Relocalization"><a href="#7-Relocalization" class="headerlink" title="7 Relocalization"></a>7 Relocalization</h1><p>本系统采用了滑动窗口和边缘化策略来限制计算复杂度，但同时也引入了<strong>累积漂移</strong>；为了消除累积漂移，作者提出了一种可与单目VIO 无缝集成的<strong>紧耦合重定位模块</strong>。重定位过程首先使用<strong>回环检测模块</strong>来判断某场景是否出现过，然后建立回环候选帧与当前帧之间的<strong>特征级关联</strong>，这些特征关联<strong>紧耦合至单目VIO 模块</strong>，在使用最小计算的情况下实现<strong>无漂移状态估计</strong>。对多个特征的多次观测可被直接用于重定位，以实现更高的定位精度与顺滑度。重定位过程如Fig. 9 (a)所示。</p>
<p><img src="/2024/01/31/vins/image-20240131193322044.png" alt="image-20240131193322044" title="figure 9"></p>
<h2 id="7-1-Loop-Detection"><a href="#7-1-Loop-Detection" class="headerlink" title="7.1 Loop Detection"></a>7.1 Loop Detection</h2><p>作者使用<strong>DBoW2</strong> 进行回环检测，除了用于单目VIO 的角点特征外，还使用额外500个BRIEF 描述子代表的角点特征，以实现更高的回环检测召回率。经过时间与几何维度的一致性检验后，DBoW2 输出若干个回环检测候选帧。本系统保留所有的BRIEF 描述子以进行特征恢复，但为了节约内存消耗会舍弃所有的原始图像数据。</p>
<h2 id="7-2-Feature-Retrieval"><a href="#7-2-Feature-Retrieval" class="headerlink" title="7.2 Feature Retrieval"></a>7.2 Feature Retrieval</h2><p>当检测到回环后，局部窗口与回环候选帧之间会通过恢复特征关联（BRIEF 描述子匹配）建立联系，作者使用两步的几何外点方法来剔除错误匹配，如Fig. 10所示：</p>
<p><img src="/2024/01/31/vins/image-20240131194802806.png" alt="image-20240131194802806" title="figure 10"></p>
<ul>
<li>2D-2D：利用RANSAC 进行基础矩阵测试；</li>
<li>3D-2D：利用RANSAC 进行PnP 测试，基于窗口内特征点的已知3D 位置及回环候选帧中的2D 观测进行PnP 测试。</li>
</ul>
<h2 id="7-3-Tightly-Coupled-Relocalization"><a href="#7-3-Tightly-Coupled-Relocalization" class="headerlink" title="7.3 Tightly Coupled Relocalization"></a>7.3 Tightly Coupled Relocalization</h2><p>在重定位中，本系统将所有回环帧的位姿设为常量（不进行优化），使用所有的IMU 观测、局部视觉观测，以及恢复的特征关联对窗口进行联合优化。其中，视觉观测模型与式17相同，除了回环帧的位姿 $(\hat{\mathbf{q}}_v^w, \hat{\mathbf{p}}_v^w)$ 被设为常量，该常量来自位姿图，或直接取自里程计输出（若是第一次重定位）。基于此，将式14更改为如下所示：</p>
<p><img src="/2024/01/31/vins/image-20240131200032028.png" alt="image-20240131200032028" title="formula 18"></p>
<p>其中，$\mathcal{L}$ 表示从回环帧中恢复的特征观测，$(l, v)$ 表示在回环帧 $v$ 中观测到的第 $l$ 个特征。</p>
<h1 id="8-Global-Pose-Graph-Optimization-and-Map-Reuse"><a href="#8-Global-Pose-Graph-Optimization-and-Map-Reuse" class="headerlink" title="8 Global Pose Graph Optimization and Map Reuse"></a>8 Global Pose Graph Optimization and Map Reuse</h1><p>在重定位之后，使用额外的位姿图优化来确保历史位姿保持全局一致。</p>
<h2 id="8-1-Four-Accumulated-Drift-Direction"><a href="#8-1-Four-Accumulated-Drift-Direction" class="headerlink" title="8.1 Four Accumulated Drift Direction"></a>8.1 Four Accumulated Drift Direction</h2><p>受益于对重力的惯性测量，roll 与 pitch 角度可在VINS 中得到完整观测，如Fig. 11所示，随着物体运动，物体的 3D 位置和旋转会在参考坐标系下发生相对变化，可通过重力向量判断水平面，从而实现对roll 和 pitch 角的确定。因此，累积漂移仅出现在 $x, y, z, yaw$ 上，为了充分利用已知信息来校正漂移，作者固定roll 和 pitch 角度，利用位姿图实现<strong>对4自由度的优化</strong>。</p>
<p><img src="/2024/01/31/vins/image-20240131200758379.png" alt="image-20240131200758379" title="figure 11"></p>
<h2 id="8-2-Adding-Keyframes-Into-the-Pose-Graph"><a href="#8-2-Adding-Keyframes-Into-the-Pose-Graph" class="headerlink" title="8.2 Adding Keyframes Into the Pose Graph"></a>8.2 Adding Keyframes Into the Pose Graph</h2><p>关键帧在VIO 处理之后被添加进位姿图中，每个关键帧在位姿图中都作为一个顶点，与其他顶点之间有两种类型的边，如Fig. 12所示。</p>
<ol>
<li>Sequential Edge：一个关键帧会与之前的关键帧之间建立序列边，序列边表示两帧之间的相对位姿转换，该转换直接取自于VIO，且该转换关系只包含平移 $\hat{\mathbf{p}}^i_{ij}$ 和yaw 角 $\hat{\psi}_{ij}$；</li>
</ol>
<p><img src="/2024/01/31/vins/image-20240131204337669.png" alt="image-20240131204337669" title="formula 19"></p>
<ol>
<li>Loop-Closure Edge：回环边的值来自重定位，同样也只包含平移和yaw 角的4自由度参数。</li>
</ol>
<p><img src="/2024/01/31/vins/image-20240131203724102.png" alt="image-20240131203724102" title="figure 12"></p>
<h2 id="8-3-4-DOF-Pose-Graph-Optimization"><a href="#8-3-4-DOF-Pose-Graph-Optimization" class="headerlink" title="8.3 4-DOF Pose Graph Optimization"></a>8.3 4-DOF Pose Graph Optimization</h2><p>定义两帧间边的残差为：</p>
<p><img src="/2024/01/31/vins/image-20240131204626147.png" alt="image-20240131204626147" title="formula 20"></p>
<p>其中，$\hat{\phi}_i, \hat{\theta}_i$ 分别是固定的roll pitch 角。</p>
<p>序列边和回环边的联合损失函数如下式所示：</p>
<p><img src="/2024/01/31/vins/image-20240131204832609.png" alt="image-20240131204832609" title="formula 21"></p>
<p>尽管紧耦合的重定位模块已经对回环检测进行了筛选，作者还是增加了Huber 核函数 $\rho(.)$ 来进一步减少错误回环带来的影响。相对应的，序列边部分不使用额外处理，这是因为VIO 已经包含了充足的外点剔除机制。</p>
<p>位姿图优化和重定位在两个独立线程进行异步运行，这使得重定位可以使用最新处理过的位姿图优化结果。</p>
<h2 id="8-4-Pose-Graph-Merging"><a href="#8-4-Pose-Graph-Merging" class="headerlink" title="8.4 Pose Graph Merging"></a>8.4 Pose Graph Merging</h2><p>位姿图不仅可以优化当前地图，而且还可以利用<strong>回环检测</strong>将当前地图与历史构建地图进行融合，如Fig. 13所示。</p>
<p><img src="/2024/01/31/vins/image-20240131205629702.png" alt="image-20240131205629702" title="figure 13"></p>

    </div>

    
    
    

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/SLAM/" rel="tag"><i class="fa fa-tag"></i> SLAM</a>
              <a href="/tags/C/" rel="tag"><i class="fa fa-tag"></i> C++</a>
              <a href="/tags/IMU/" rel="tag"><i class="fa fa-tag"></i> IMU</a>
              <a href="/tags/VINS/" rel="tag"><i class="fa fa-tag"></i> VINS</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/01/30/dynaslam/" rel="prev" title="论文记录 DynaSLAM_Tracking, Mapping, and Inpainting in Dynamic Scenes">
      <i class="fa fa-chevron-left"></i> 论文记录 DynaSLAM_Tracking, Mapping, and Inpainting in Dynamic Scenes
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/01/31/laneloc/" rel="next" title="论文记录 LaneLoc_Lane marking based localization using highly accurate maps">
      论文记录 LaneLoc_Lane marking based localization using highly accurate maps <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Introduction"><span class="nav-text">1 Introduction</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Overview"><span class="nav-text">3 Overview</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Measurement-Preprocessing"><span class="nav-text">4 Measurement Preprocessing</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-Vision-Processing-Front-End"><span class="nav-text">4.1 Vision Processing Front End</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-IMU-Preintegration"><span class="nav-text">4.2 IMU Preintegration</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-1-IMU-Noise-and-Bias"><span class="nav-text">4.2.1 IMU Noise and Bias</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-2-Preintegration"><span class="nav-text">4.2.2 Preintegration</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-3-Bias-Correction"><span class="nav-text">4.2.3 Bias Correction</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-Estimator-Initialization"><span class="nav-text">5 Estimator Initialization</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-Vision-Only-SfM-in-Sliding-Window"><span class="nav-text">5.1 Vision-Only SfM in Sliding Window</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-Visual-Inertial-Alignment"><span class="nav-text">5.2 Visual-Inertial Alignment</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-1-Gyroscope-Bias-Calibration"><span class="nav-text">5.2.1 Gyroscope Bias Calibration</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-2-Velocity-Gravity-Vector-and-Metric-Scale-Initialization"><span class="nav-text">5.2.2 Velocity, Gravity Vector, and Metric Scale Initialization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-3-Gravity-Refinement"><span class="nav-text">5.2.3 Gravity Refinement</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-4-Completing-Initialization"><span class="nav-text">5.2.4 Completing Initialization</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-Tightly-Coupled-Monocular-VIO"><span class="nav-text">6 Tightly Coupled Monocular VIO</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#6-1-Formulation"><span class="nav-text">6.1 Formulation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-2-IMU-Measurement-Residual"><span class="nav-text">6.2 IMU Measurement Residual</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-3-Visual-Measurement-Residual"><span class="nav-text">6.3 Visual Measurement Residual</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-4-Marginalization"><span class="nav-text">6.4 Marginalization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-5-Motion-Only-Visual-Inertial-Optimization-for-Camera-Rate-State-Estimation"><span class="nav-text">6.5 Motion-Only Visual-Inertial Optimization for Camera-Rate State Estimation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-6-IMU-Forward-Propagation-for-IMU-Rate-State-Estimation"><span class="nav-text">6.6 IMU Forward Propagation for IMU-Rate State Estimation</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-Relocalization"><span class="nav-text">7 Relocalization</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#7-1-Loop-Detection"><span class="nav-text">7.1 Loop Detection</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-2-Feature-Retrieval"><span class="nav-text">7.2 Feature Retrieval</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-3-Tightly-Coupled-Relocalization"><span class="nav-text">7.3 Tightly Coupled Relocalization</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#8-Global-Pose-Graph-Optimization-and-Map-Reuse"><span class="nav-text">8 Global Pose Graph Optimization and Map Reuse</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#8-1-Four-Accumulated-Drift-Direction"><span class="nav-text">8.1 Four Accumulated Drift Direction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-2-Adding-Keyframes-Into-the-Pose-Graph"><span class="nav-text">8.2 Adding Keyframes Into the Pose Graph</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-3-4-DOF-Pose-Graph-Optimization"><span class="nav-text">8.3 4-DOF Pose Graph Optimization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-4-Pose-Graph-Merging"><span class="nav-text">8.4 Pose Graph Merging</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Echo"
      src="/images/snoopy.jpg">
  <p class="site-author-name" itemprop="name">Echo</p>
  <div class="site-description" itemprop="description">To know, read. To learn, write. To master, teach.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">84</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">21</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">41</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:xrzhao404@outlook.com" title="E-Mail → mailto:xrzhao404@outlook.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-robot"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Echo</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '64px',
  right: 'unset',
  left: '32px',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
